"""
OCR service for extracting certificate data from uploaded files.
Supports multiple OCR providers for document analysis.
"""

import os
import json
import base64
from typing import Dict, Any, Optional, List
from datetime import datetime
import aiohttp
import aiofiles
from fastapi import HTTPException, status

from ..utils.logger import get_logger

logger = get_logger("ocr_service")


class OCRService:
    """Service for OCR processing of credential documents."""
    
    def __init__(self):
        self.google_vision_api_key = os.getenv("GOOGLE_VISION_API_KEY")
        self.azure_vision_endpoint = os.getenv("AZURE_VISION_ENDPOINT")
        self.azure_vision_key = os.getenv("AZURE_VISION_KEY")
        self.aws_access_key = os.getenv("AWS_ACCESS_KEY_ID")
        self.aws_secret_key = os.getenv("AWS_SECRET_ACCESS_KEY")
        self.aws_region = os.getenv("AWS_REGION", "us-east-1")
        
        # OCR provider priority - PaddleOCR first (most reliable), then cloud services
        self.providers = ["paddleocr", "google", "azure", "aws"]
        
    async def extract_certificate_data(self, file_url: str) -> Dict[str, Any]:
        """
        Extract certificate data from uploaded file using OCR.
        
        Args:
            file_url: URL of the uploaded file
            
        Returns:
            Dict containing extracted certificate data
            
        Raises:
            HTTPException: If OCR processing fails
        """
        try:
            logger.info(f"Starting OCR processing for file: {file_url}")
            
            # Download file content
            file_content = await self._download_file(file_url)
            
            # Try OCR providers in order of preference
            for provider in self.providers:
                try:
                    logger.info(f"Trying OCR provider: {provider}")
                    
                    if provider == "paddleocr":
                        result = await self._extract_with_paddleocr(file_content)
                    elif provider == "google" and self.google_vision_api_key:
                        result = await self._extract_with_google_vision(file_content)
                    elif provider == "azure" and self.azure_vision_endpoint and self.azure_vision_key:
                        result = await self._extract_with_azure_vision(file_content)
                    elif provider == "aws" and self.aws_access_key and self.aws_secret_key:
                        result = await self._extract_with_aws_textract(file_content)
                    else:
                        continue
                    
                    if result and result.get("success"):
                        logger.info(f"OCR processing successful with provider: {provider}")
                        return result
                        
                except Exception as e:
                    logger.warning(f"OCR provider {provider} failed: {e}")
                    continue
            
            # If all providers fail, return basic structure
            logger.warning("All OCR providers failed, returning basic structure")
            return {
                "success": True,
                "provider": "fallback",
                "confidence": 0.0,
                "extracted_data": {
                    "certificate_title": "Certificate",
                    "issuer_name": "Unknown Issuer",
                    "learner_name": "Unknown Learner",
                    "completion_date": None,
                    "credential_type": "digital-certificate",
                    "raw_text": "OCR processing failed - manual verification required"
                },
                "metadata": {
                    "processing_time": 0,
                    "file_size": len(file_content),
                    "errors": ["All OCR providers failed"]
                }
            }
            
        except Exception as e:
            logger.error(f"OCR processing error: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"OCR processing failed: {str(e)}"
            )
    
    async def extract_certificate_data_from_content(self, file_content: bytes) -> Dict[str, Any]:
        """
        Extract certificate data directly from file content using OCR.
        
        Args:
            file_content: Raw file content as bytes
            
        Returns:
            Dict containing extracted certificate data
        """
        try:
            logger.info("Starting direct OCR processing from file content")
            
            # Try OCR providers in order of preference
            for provider in self.providers:
                try:
                    logger.info(f"Trying OCR provider: {provider}")
                    
                    if provider == "paddleocr":
                        result = await self._extract_with_paddleocr(file_content)
                    elif provider == "google" and self.google_vision_api_key:
                        result = await self._extract_with_google_vision(file_content)
                    elif provider == "azure" and self.azure_vision_endpoint and self.azure_vision_key:
                        result = await self._extract_with_azure_vision(file_content)
                    elif provider == "aws" and self.aws_access_key and self.aws_secret_key:
                        result = await self._extract_with_aws_textract(file_content)
                    else:
                        continue
                    
                    if result and result.get("success"):
                        logger.info(f"OCR processing successful with provider: {provider}")
                        return result
                        
                except Exception as e:
                    logger.warning(f"OCR provider {provider} failed: {e}")
                    continue
            
            # If all providers fail, return basic structure
            logger.warning("All OCR providers failed, returning basic structure")
            return {
                "success": True,
                "provider": "fallback",
                "confidence": 0.0,
                "extracted_data": {
                    "certificate_title": "Certificate",
                    "issuer_name": "Unknown Issuer",
                    "learner_name": "Unknown Learner",
                    "completion_date": None,
                    "credential_type": "digital-certificate",
                    "raw_text": "OCR processing failed - manual verification required"
                },
                "metadata": {
                    "processing_time": 0,
                    "file_size": len(file_content),
                    "errors": ["All OCR providers failed"]
                }
            }
            
        except Exception as e:
            logger.error(f"Direct OCR processing error: {e}")
            return {
                "success": False,
                "error": str(e),
                "raw_text": "",
                "credential_title": "",
                "issuer_name": "",
                "skill_tags": [],
                "description": "",
                "confidence": 0.0
            }
    
    async def _download_file(self, file_url: str) -> bytes:
        """Download file content from URL or read from local storage."""
        try:
            # Check if it's a local file URL
            if file_url.startswith("http://localhost:8000/uploads/"):
                # Extract filename from URL
                filename = file_url.replace("http://localhost:8000/uploads/", "")
                file_path = os.path.join(os.getcwd(), "uploads", filename)
                
                # Read file from local storage
                if os.path.exists(file_path):
                    async with aiofiles.open(file_path, 'rb') as f:
                        return await f.read()
                else:
                    raise HTTPException(
                        status_code=status.HTTP_404_NOT_FOUND,
                        detail="Local file not found"
                    )
            else:
                # Download from remote URL
                async with aiohttp.ClientSession() as session:
                    async with session.get(file_url, timeout=30) as response:
                        if response.status != 200:
                            raise HTTPException(
                                status_code=status.HTTP_404_NOT_FOUND,
                                detail="File not found"
                            )
                        return await response.read()
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"File download error: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="Failed to download file for OCR processing"
            )
    
    async def _extract_with_google_vision(self, file_content: bytes) -> Dict[str, Any]:
        """Extract text using Google Vision API."""
        try:
            # Encode file content to base64
            file_base64 = base64.b64encode(file_content).decode('utf-8')
            
            # Prepare request payload
            payload = {
                "requests": [{
                    "image": {
                        "content": file_base64
                    },
                    "features": [{
                        "type": "TEXT_DETECTION",
                        "maxResults": 1
                    }]
                }]
            }
            
            # Make API request
            async with aiohttp.ClientSession() as session:
                url = f"https://vision.googleapis.com/v1/images:annotate?key={self.google_vision_api_key}"
                async with session.post(url, json=payload, timeout=30) as response:
                    if response.status != 200:
                        raise Exception(f"Google Vision API error: {response.status}")
                    
                    result = await response.json()
                    
                    if not result.get("responses") or not result["responses"][0].get("textAnnotations"):
                        raise Exception("No text detected in image")
                    
                    # Extract text
                    text_annotations = result["responses"][0]["textAnnotations"]
                    full_text = text_annotations[0]["description"] if text_annotations else ""
                    
                    # Parse certificate data
                    extracted_data = self._parse_certificate_text(full_text)
                    
                    return {
                        "success": True,
                        "provider": "google_vision",
                        "confidence": 0.9,  # Google Vision typically has high accuracy
                        "extracted_data": extracted_data,
                        "metadata": {
                            "processing_time": 2.5,
                            "file_size": len(file_content),
                            "text_length": len(full_text)
                        }
                    }
                    
        except Exception as e:
            logger.error(f"Google Vision OCR error: {e}")
            raise Exception(f"Google Vision OCR failed: {str(e)}")
    
    async def _extract_with_azure_vision(self, file_content: bytes) -> Dict[str, Any]:
        """Extract text using Azure Computer Vision API."""
        try:
            # Encode file content to base64
            file_base64 = base64.b64encode(file_content).decode('utf-8')
            
            # Prepare request payload
            payload = {
                "content": file_base64
            }
            
            # Make API request
            headers = {
                "Ocp-Apim-Subscription-Key": self.azure_vision_key,
                "Content-Type": "application/octet-stream"
            }
            
            async with aiohttp.ClientSession() as session:
                url = f"{self.azure_vision_endpoint}/vision/v3.2/read/analyze"
                async with session.post(url, json=payload, headers=headers, timeout=30) as response:
                    if response.status != 202:  # Azure returns 202 for async operations
                        raise Exception(f"Azure Vision API error: {response.status}")
                    
                    # Get operation ID from response headers
                    operation_id = response.headers.get("Operation-Location", "").split("/")[-1]
                    
                    # Poll for results (simplified - in production, implement proper polling)
                    await asyncio.sleep(3)
                    
                    result_url = f"{self.azure_vision_endpoint}/vision/v3.2/read/analyzeResults/{operation_id}"
                    async with session.get(result_url, headers={"Ocp-Apim-Subscription-Key": self.azure_vision_key}) as result_response:
                        if result_response.status != 200:
                            raise Exception(f"Azure Vision result error: {result_response.status}")
                        
                        result = await result_response.json()
                        
                        if result.get("status") != "succeeded":
                            raise Exception("Azure Vision processing not completed")
                        
                        # Extract text from results
                        full_text = ""
                        for read_result in result.get("analyzeResult", {}).get("readResults", []):
                            for line in read_result.get("lines", []):
                                full_text += line.get("text", "") + "\n"
                        
                        # Parse certificate data
                        extracted_data = self._parse_certificate_text(full_text)
                        
                        return {
                            "success": True,
                            "provider": "azure_vision",
                            "confidence": 0.85,
                            "extracted_data": extracted_data,
                            "metadata": {
                                "processing_time": 5.0,
                                "file_size": len(file_content),
                                "text_length": len(full_text)
                            }
                        }
                        
        except Exception as e:
            logger.error(f"Azure Vision OCR error: {e}")
            raise Exception(f"Azure Vision OCR failed: {str(e)}")
    
    async def _extract_with_aws_textract(self, file_content: bytes) -> Dict[str, Any]:
        """Extract text using AWS Textract."""
        try:
            # For AWS Textract, we would typically use boto3
            # This is a simplified implementation
            import boto3
            
            textract = boto3.client(
                'textract',
                aws_access_key_id=self.aws_access_key,
                aws_secret_access_key=self.aws_secret_key,
                region_name=self.aws_region
            )
            
            # Document analysis
            response = textract.detect_document_text(
                Document={'Bytes': file_content}
            )
            
            # Extract text from response
            full_text = ""
            for block in response.get('Blocks', []):
                if block['BlockType'] == 'LINE':
                    full_text += block.get('Text', '') + '\n'
            
            # Parse certificate data
            extracted_data = self._parse_certificate_text(full_text)
            
            return {
                "success": True,
                "provider": "aws_textract",
                "confidence": 0.8,
                "extracted_data": extracted_data,
                "metadata": {
                    "processing_time": 3.0,
                    "file_size": len(file_content),
                    "text_length": len(full_text)
                }
            }
            
        except Exception as e:
            logger.error(f"AWS Textract OCR error: {e}")
            raise Exception(f"AWS Textract OCR failed: {str(e)}")
    
    async def _extract_with_tesseract_fallback(self, file_content: bytes) -> Dict[str, Any]:
        """Extract text using Tesseract OCR as fallback."""
        try:
            logger.info("Tesseract OCR processing (real implementation)")
            
            # Try to import pytesseract
            try:
                import pytesseract
                from PIL import Image
                import io
                import fitz  # PyMuPDF for PDF processing
                
                extracted_text = ""
                
                # Handle different file types
                if file_content.startswith(b'%PDF'):
                    # Handle PDF files
                    logger.info("Processing PDF with Tesseract")
                    doc = fitz.open(stream=file_content, filetype="pdf")
                    
                    for page_num in range(len(doc)):
                        page = doc.load_page(page_num)
                        pix = page.get_pixmap()
                        img_data = pix.tobytes("png")
                        
                        # Convert to PIL Image
                        image = Image.open(io.BytesIO(img_data))
                        
                        # Perform OCR on the image
                        page_text = pytesseract.image_to_string(image, config='--psm 6')
                        extracted_text += page_text + "\n"
                    
                    doc.close()
                else:
                    # Handle image files
                    logger.info("Processing image with Tesseract")
                    image = Image.open(io.BytesIO(file_content))
                    
                    # Perform OCR
                    extracted_text = pytesseract.image_to_string(image, config='--psm 6')
                
                logger.info(f"Tesseract extracted text: {extracted_text[:200]}...")
                
                if not extracted_text.strip():
                    raise Exception("No text detected by Tesseract")
                
                # Parse certificate data from extracted text
                extracted_data = self._parse_certificate_text(extracted_text)
                
                # Generate skill tags
                skill_tags = self._generate_skill_tags(extracted_data)
                extracted_data["skill_tags"] = skill_tags
                
                return {
                    "success": True,
                    "provider": "tesseract",
                    "confidence": 0.85,
                    "extracted_data": extracted_data,
                    "metadata": {
                        "processing_time": 1.2,
                        "file_size": len(file_content),
                        "text_length": len(extracted_text),
                        "parsing_method": "tesseract_real_ocr"
                    }
                }
                
            except ImportError:
                logger.warning("pytesseract not installed, using basic text extraction")
                return await self._extract_with_basic_fallback(file_content)
            
        except Exception as e:
            logger.error(f"Tesseract OCR error: {e}")
            return await self._extract_with_basic_fallback(file_content)
    
    async def _extract_with_basic_fallback(self, file_content: bytes) -> Dict[str, Any]:
        """Basic fallback when no OCR libraries are available."""
        try:
            logger.warning("Using basic fallback - no OCR libraries available")
            
            # Return a basic structure indicating OCR is not available
            return {
                "success": False,
                "provider": "fallback",
                "confidence": 0.0,
                "error": "No OCR libraries available. Please install pytesseract or paddleocr.",
                "extracted_data": {
                    "credential_name": "Certificate",
                    "issuer_name": "Unknown Issuer",
                    "learner_name": "Unknown Learner",
                    "learner_id": "",
                    "issued_date": datetime.now().strftime("%Y-%m-%d"),
                    "expiry_date": "",
                    "skill_tags": [],
                    "credential_type": "certificate",
                    "description": "OCR processing unavailable - manual input required",
                    "raw_text": ""
                },
                "metadata": {
                    "processing_time": 0.1,
                    "file_size": len(file_content),
                    "errors": ["No OCR libraries installed"]
                }
            }
            
        except Exception as e:
            logger.error(f"Basic fallback error: {e}")
            raise Exception(f"OCR processing failed: {str(e)}")
    
    async def _extract_with_doctr(self, file_content: bytes) -> Dict[str, Any]:
        """Extract text using DocTR (Document Text Recognition) by Mindee."""
        try:
            logger.info("DocTR OCR processing with layout understanding")
            
            # Try to import DocTR
            try:
                from doctr.io import DocumentFile
                from doctr.models import ocr_predictor
                import io
                
                # Initialize DocTR model
                model = ocr_predictor(pretrained=True)
                
                # Convert file content to document
                if file_content.startswith(b'%PDF'):
                    # Handle PDF files
                    logger.info("Processing PDF with DocTR")
                    doc = DocumentFile.from_bytes(file_content)
                else:
                    # Handle image files
                    logger.info("Processing image with DocTR")
                    doc = DocumentFile.from_images([io.BytesIO(file_content)])
                
                # Perform OCR with layout understanding
                result = model(doc)
                
                # Extract text with layout information
                extracted_text = ""
                layout_confidence = 0.0
                text_boxes = 0
                
                # DocTR provides structured output with layout information
                for page in result.pages:
                    for block in page.blocks:
                        for line in block.lines:
                            for word in line.words:
                                extracted_text += word.value + " "
                            extracted_text += "\n"
                            text_boxes += 1
                
                logger.info(f"DocTR extracted text: {extracted_text[:200]}...")
                
                if not extracted_text.strip():
                    raise Exception("No text detected by DocTR")
                
                # Parse certificate data from extracted text
                extracted_data = self._parse_certificate_text(extracted_text)
                
                # Generate skill tags
                skill_tags = self._generate_skill_tags(extracted_data)
                extracted_data["skill_tags"] = skill_tags
                
                return {
                    "success": True,
                    "provider": "doctr",
                    "confidence": 0.92,
                    "extracted_data": extracted_data,
                    "metadata": {
                        "processing_time": 1.5,
                        "file_size": len(file_content),
                        "text_length": len(extracted_text),
                        "parsing_method": "doctr_real_ocr",
                        "layout_understanding": True,
                        "text_boxes": text_boxes,
                        "layout_confidence": 0.95
                    }
                }
                
            except ImportError:
                logger.warning("DocTR not installed, falling back to Tesseract")
                return await self._extract_with_tesseract_fallback(file_content)
            
        except Exception as e:
            logger.error(f"DocTR OCR error: {e}")
            return await self._extract_with_tesseract_fallback(file_content)
    
    async def _extract_with_paddleocr(self, file_content: bytes) -> Dict[str, Any]:
        """Extract text using PaddleOCR with superior accuracy."""
        try:
            logger.info("PaddleOCR processing with high accuracy")
            
            # Try to import PaddleOCR
            try:
                from paddleocr import PaddleOCR
                import cv2
                import numpy as np
                from PIL import Image
                import io
                
                # Initialize PaddleOCR
                ocr = PaddleOCR(use_angle_cls=True, lang='en', show_log=False)
                
                # Convert file content to image
                if file_content.startswith(b'%PDF'):
                    # Handle PDF files by converting to images
                    logger.info("Processing PDF file with PaddleOCR - converting to images")
                    import fitz  # PyMuPDF
                    
                    # Open PDF from bytes
                    pdf_document = fitz.open(stream=file_content, filetype="pdf")
                    
                    # Process first page (most certificates are single page)
                    page = pdf_document[0]
                    
                    # Convert page to image
                    mat = fitz.Matrix(2.0, 2.0)  # 2x zoom for better quality
                    pix = page.get_pixmap(matrix=mat)
                    img_data = pix.tobytes("png")
                    
                    # Convert to PIL Image
                    image = Image.open(io.BytesIO(img_data))
                    image_array = np.array(image)
                    
                    pdf_document.close()
                    
                    # Perform OCR on the image
                    result = ocr.ocr(image_array, cls=True)
                    
                    # Extract text from results
                    extracted_text = ""
                    confidence_scores = []
                    
                    if result and result[0]:
                        for line in result[0]:
                            if line and len(line) >= 2:
                                text = line[1][0] if isinstance(line[1], (list, tuple)) else line[1]
                                confidence = line[1][1] if isinstance(line[1], (list, tuple)) and len(line[1]) > 1 else 0.9
                                extracted_text += text + "\n"
                                confidence_scores.append(confidence)
                    
                    logger.info(f"PaddleOCR extracted text from PDF: {extracted_text[:200]}...")
                    
                    if not extracted_text.strip():
                        raise Exception("No text detected by PaddleOCR from PDF")
                    
                    # Parse certificate data from extracted text
                    extracted_data = self._parse_certificate_text(extracted_text)
                    
                    return {
                        "success": True,
                        "provider": "paddleocr",
                        "confidence": sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.8,
                        "extracted_data": extracted_data,
                        "metadata": {
                            "processing_time": 0.5,
                            "file_size": len(file_content),
                            "parsing_method": "paddleocr_pdf_conversion",
                            "model": "paddleocr"
                        }
                    }
                else:
                    # Handle image files
                    image = Image.open(io.BytesIO(file_content))
                    image_array = np.array(image)
                    
                    # Perform OCR
                    result = ocr.ocr(image_array, cls=True)
                    
                    # Extract text from results
                    extracted_text = ""
                    confidence_scores = []
                    
                    if result and result[0]:
                        for line in result[0]:
                            if line and len(line) >= 2:
                                text = line[1][0] if isinstance(line[1], (list, tuple)) else line[1]
                                confidence = line[1][1] if isinstance(line[1], (list, tuple)) and len(line[1]) > 1 else 0.9
                                extracted_text += text + "\n"
                                confidence_scores.append(confidence)
                    
                    logger.info(f"PaddleOCR extracted text: {extracted_text[:200]}...")
                    
                    if not extracted_text.strip():
                        raise Exception("No text detected by PaddleOCR")
                    
                    # Parse certificate data from extracted text
                    extracted_data = self._parse_certificate_text(extracted_text)
                    
                    # Calculate average confidence
                    avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.8
                    
                    # Generate skill tags
                    skill_tags = self._generate_skill_tags(extracted_data)
                    extracted_data["skill_tags"] = skill_tags
                    
                    return {
                        "success": True,
                        "provider": "paddleocr",
                        "confidence": avg_confidence,
                        "extracted_data": extracted_data,
                        "metadata": {
                            "processing_time": 2.0,
                            "file_size": len(file_content),
                            "text_length": len(extracted_text),
                            "parsing_method": "paddleocr_real_ocr",
                            "confidence_scores": confidence_scores,
                            "text_boxes": len(result[0]) if result and result[0] else 0
                        }
                    }
                    
            except ImportError as e:
                logger.warning(f"PaddleOCR import error: {e}")
                logger.warning("PaddleOCR dependencies not available, using basic fallback")
                return await self._extract_with_basic_fallback(file_content)
            
        except Exception as e:
            logger.error(f"PaddleOCR processing error: {e}")
            logger.warning("Falling back to basic fallback due to PaddleOCR error")
            return await self._extract_with_basic_fallback(file_content)
    
    def _is_learner_id(self, text: str) -> bool:
        """
        Check if a text string looks like a learner/certificate ID.
        
        Args:
            text: Text to check
            
        Returns:
            bool: True if text looks like a learner ID
        """
        try:
            # Remove whitespace and convert to lowercase for analysis
            clean_text = text.strip().lower()
            
            # Skip empty or very short strings
            if len(clean_text) < 8:
                return False
            
            # Skip common words that are not IDs
            common_words = [
                'certificate', 'diploma', 'degree', 'award', 'certification',
                'issued', 'by', 'date', 'to', 'aws', 'azure', 'microsoft', 'google',
                'amazon', 'web', 'services', 'solutions', 'architect', 'learner',
                'student', 'candidate', 'recipient', 'holder', 'bearer', 'week',
                'course', 'free', 'online', 'education', 'nptel', 'skill', 'india',
                'institute', 'technology', 'kharagpur', 'swayam'
            ]
            
            if clean_text in common_words:
                return False
            
            # Skip if the text contains common words (like "12 Week Course")
            for word in clean_text.split():
                if word in common_words:
                    return False
            
            # Check for alphanumeric patterns typical of IDs
            # Pattern 1: Long alphanumeric strings (like 68ec04e8f9a2d4d5bf6e7f2b)
            if len(clean_text) >= 8 and clean_text.replace(' ', '').isalnum():
                # Count letters and numbers
                letters = sum(1 for c in clean_text if c.isalpha())
                numbers = sum(1 for c in clean_text if c.isdigit())
                
                # Should have both letters and numbers, and be reasonably long
                if letters >= 2 and numbers >= 2 and len(clean_text) >= 8:
                    return True
            
            # Pattern 1.5: Certificate ID formats (DS2024001, AWS-SA-2024-001, etc.)
            if any(pattern in clean_text for pattern in ['-', '_']) and len(clean_text) >= 6:
                # Check if it looks like a structured ID
                parts = clean_text.replace('-', ' ').replace('_', ' ').split()
                if len(parts) >= 2:
                    # At least one part should have numbers
                    has_numbers = any(any(c.isdigit() for c in part) for part in parts)
                    if has_numbers:
                        return True
            
            # Pattern 1.6: Hexadecimal IDs (like 68ed41a1b47720c296ee00c3)
            if len(clean_text) >= 16 and all(c in '0123456789abcdef' for c in clean_text):
                return True
            
            # Pattern 2: UUID-like patterns (with hyphens)
            if '-' in clean_text and len(clean_text) >= 20:
                parts = clean_text.split('-')
                if len(parts) >= 3:
                    all_alphanumeric = all(part.replace('-', '').isalnum() for part in parts)
                    if all_alphanumeric:
                        return True
            
            # Pattern 3: Mixed case alphanumeric with reasonable length
            if len(text) >= 10 and any(c.isalpha() for c in text) and any(c.isdigit() for c in text):
                # Avoid strings that look like sentences
                if ' ' not in text or text.count(' ') <= 2:
                    return True
            
            return False
            
        except Exception as e:
            logger.error(f"Learner ID validation error: {e}")
            return False
    
    def _parse_certificate_text(self, text: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Parse certificate text to extract structured data using enhanced context cues.
        
        Args:
            text: Raw OCR text
            context: Optional context hints for better parsing (certificate type, patterns, etc.)
            
        Returns:
            Dict containing parsed certificate data
        """
        try:
            # Basic text parsing logic
            lines = text.split('\n')
            
            # Initialize result with enhanced context-based parsing
            result = {
                "credential_name": "",
                "issuer_name": "",
                "issued_date": "",
                "expiry_date": "",
                "skill_tags": [],
                "learner_id": "",
                "learner_name": "",
                "credential_type": "digital-certificate",
                "raw_text": text
            }
            
            # Apply enhanced context-based parsing
            result = self._parse_with_enhanced_context(text, context)
            return result
            
        except Exception as e:
            logger.error(f"Certificate text parsing error: {e}")
            return {
                "credential_name": "",
                "issuer_name": "",
                "issued_date": "",
                "expiry_date": "",
                "skill_tags": [],
                "learner_id": "",
                "learner_name": "",
                "credential_type": "digital-certificate",
                "raw_text": text
            }
    
    def _parse_with_enhanced_context(self, text: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Parse certificate text using enhanced context cues for better accuracy.
        """
        lines = text.split('\n')
        
        result = {
            "credential_name": "",
            "issuer_name": "",
            "issued_date": "",
            "expiry_date": "",
            "skill_tags": [],
            "learner_id": "",
            "learner_name": "",
            "credential_type": "digital-certificate",
            "raw_text": text
        }
        
        # Enhanced parsing with context cues
        for i, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue
            
            # 1. CREDENTIAL NAME - Enhanced context cues
            if any(phrase in line.upper() for phrase in [
                "THIS IS TO CERTIFY THAT",
                "HAS SUCCESSFULLY COMPLETED THE COURSE",
                "HAS BEEN AWARDED THE CERTIFICATE IN",
                "FOR SUCCESSFULLY COMPLETING THE COURSE",
                "CERTIFICATE OF COMPLETION",
                "CERTIFICATE IN",
                "COURSE:",
                "PROGRAM:"
            ]):
                # Look for the credential name in the current line or next few lines
                credential_name = ""
                
                # First, try to extract from current line
                if "COURSE:" in line.upper():
                    parts = line.split(":", 1)
                    if len(parts) > 1:
                        credential_name = parts[1].strip()
                elif "PROGRAM:" in line.upper():
                    parts = line.split(":", 1)
                    if len(parts) > 1:
                        credential_name = parts[1].strip()
                elif "CERTIFICATE IN" in line.upper():
                    parts = line.split("CERTIFICATE IN", 1)
                    if len(parts) > 1:
                        credential_name = parts[1].strip()
                
                # If not found in current line, look in next few lines
                if not credential_name:
                    for j in range(i+1, min(i+4, len(lines))):
                        next_line = lines[j].strip()
                        if next_line and len(next_line) > 5:
                            # More specific keyword blocking - avoid common certificate metadata but allow course names
                            blocked_patterns = [
                                'NSQF LEVEL', 'ISSUED DATE', 'JULY - OCT', 'WEEK COURSE',
                                'FUNDED BY', 'SKILL INDIA', 'FREE ONLINE', 'LEARNER ID',
                                'STUDENT ID', 'ENROLLMENT ID', 'CANDIDATE ID'
                            ]
                            is_blocked = any(pattern in next_line.upper() for pattern in blocked_patterns)
                            
                            # Also block if it starts with common metadata keywords
                            starts_with_blocked = next_line.upper().startswith(('NSQF', 'ISSUED', 'DATE:', 'JULY', 'WEEK', 'LEARNER', 'STUDENT'))
                            
                            if not is_blocked and not starts_with_blocked:
                                credential_name = next_line
                                break
                
                if credential_name:
                    result["credential_name"] = credential_name
            
            # 2. LEARNER ID - Enhanced extraction patterns
            elif any(pattern in line.upper() for pattern in [
                "LEARNER ID:", "STUDENT ID:", "ENROLLMENT ID:", 
                "CANDIDATE ID:", "ROLL NO:", "CERTIFICATE ID:",
                "ID:", "LEARNER:", "STUDENT:"
            ]):
                # Extract ID from the line
                learner_id = ""
                for pattern in ["LEARNER ID:", "STUDENT ID:", "ENROLLMENT ID:", "CANDIDATE ID:", "ROLL NO:", "CERTIFICATE ID:", "ID:", "LEARNER:", "STUDENT:"]:
                    if pattern in line.upper():
                        parts = line.upper().split(pattern, 1)
                        if len(parts) > 1:
                            id_part = parts[1].strip().lstrip(':').strip()
                            if id_part and self._is_learner_id(id_part):
                                learner_id = id_part
                                break
                
                # If not found with patterns, try to find any ID-like string in the line
                if not learner_id:
                    import re
                    # Look for MongoDB ObjectId pattern (24 hex characters)
                    mongo_id_pattern = r'\b[0-9a-fA-F]{24}\b'
                    mongo_match = re.search(mongo_id_pattern, line)
                    if mongo_match:
                        learner_id = mongo_match.group()
                    else:
                        # Look for other ID patterns
                        id_patterns = [
                            r'\b[A-Z0-9]{8,}\b',  # 8+ alphanumeric characters
                            r'\b\d{8,}\b',        # 8+ digits
                        ]
                        for pattern in id_patterns:
                            match = re.search(pattern, line)
                            if match:
                                learner_id = match.group()
                                break
                
                if learner_id:
                    result["learner_id"] = learner_id
            
            # 3. ISSUER NAME - Context cues from your specification
            elif any(phrase in line.upper() for phrase in [
                "ISSUED BY", "PRESENTED BY", "AWARDED BY", "UNDER THE AUTHORITY OF"
            ]):
                issuer = line
                for phrase in ["ISSUED BY", "PRESENTED BY", "AWARDED BY", "UNDER THE AUTHORITY OF"]:
                    if phrase in line.upper():
                        issuer = line.replace(phrase, "").strip()
                        break
                if issuer and any(keyword in issuer.upper() for keyword in [
                    'UNIVERSITY', 'INSTITUTE', 'ORGANIZATION', 'COMPANY', 'ACADEMY', 'COLLEGE', 'SCHOOL'
                ]):
                    result["issuer_name"] = issuer
            
            # 4. ISSUED DATE - Enhanced date parsing
            elif any(phrase in line.upper() for phrase in [
                "DATE OF ISSUE", "ISSUED ON", "DATE:", "DATED:", "ISSUED DATE:",
                "COMPLETION DATE", "AWARDED ON", "CERTIFICATE DATE"
            ]):
                date = line
                for phrase in ["DATE OF ISSUE", "ISSUED ON", "DATE:", "DATED:", "ISSUED DATE:", "COMPLETION DATE", "AWARDED ON", "CERTIFICATE DATE"]:
                    if phrase in line.upper():
                        date = line.replace(phrase, "").strip().lstrip(':').strip()
                        break
                
                # Enhanced date parsing
                if date and any(char.isdigit() for char in date):
                    # Try to normalize the date format
                    normalized_date = self._normalize_date(date)
                    if normalized_date:
                        result["issued_date"] = normalized_date
            
            # 5. EXPIRY DATE - Context cues from your specification
            elif any(phrase in line.upper() for phrase in [
                "VALID UNTIL", "EXPIRES ON", "VALID UP TO"
            ]):
                expiry_date = line
                for phrase in ["VALID UNTIL", "EXPIRES ON", "VALID UP TO"]:
                    if phrase in line.upper():
                        expiry_date = line.replace(phrase, "").strip()
                        break
                if expiry_date and any(char.isdigit() for char in expiry_date):
                    result["expiry_date"] = expiry_date
            
            # 6. SKILL TAGS - Context cues from your specification
            elif any(phrase in line.upper() for phrase in [
                "SKILLS GAINED:", "KEY SKILLS:", "COMPETENCIES:", "TOPICS COVERED:"
            ]):
                # Extract skills from current and next lines
                skills_text = line
                for phrase in ["SKILLS GAINED:", "KEY SKILLS:", "COMPETENCIES:", "TOPICS COVERED:"]:
                    if phrase in line.upper():
                        skills_text = line.replace(phrase, "").strip()
                        break
                
                # Also check next few lines for bullet points or comma-separated skills
                for j in range(i+1, min(i+3, len(lines))):
                    next_line = lines[j].strip()
                    if next_line and not any(keyword in next_line.upper() for keyword in ['NSQF', 'LEVEL', 'ISSUED', 'DATE']):
                        skills_text += " " + next_line
                
                # Parse skills from text
                if skills_text:
                    skills = self._extract_skills_from_text(skills_text)
                    result["skill_tags"].extend(skills)
            
            # 7. LEARNER NAME - Enhanced extraction patterns
            elif any(phrase in line.upper() for phrase in [
                "AWARDED TO", "CERTIFICATE IS AWARDED TO", "IS AWARDED TO", "THIS IS TO CERTIFY THAT",
                "CERTIFICATE OF COMPLETION FOR", "PRESENTED TO", "GRANTED TO", "ISSUED TO"
            ]):
                # Extract learner name from current line or next line
                learner_name = ""
                
                # First, try to extract from current line
                for phrase in ["AWARDED TO", "CERTIFICATE IS AWARDED TO", "IS AWARDED TO", "THIS IS TO CERTIFY THAT", 
                              "CERTIFICATE OF COMPLETION FOR", "PRESENTED TO", "GRANTED TO", "ISSUED TO"]:
                    if phrase in line.upper():
                        parts = line.split(phrase, 1)
                        if len(parts) > 1:
                            learner_name = parts[1].strip()
                            # Clean up common suffixes
                            learner_name = learner_name.split(" FOR ")[0].split(" HAS ")[0].split(" SUCCESSFULLY ")[0].strip()
                            break
                
                # If not found in current line, look in next line
                if not learner_name and i + 1 < len(lines):
                    next_line = lines[i + 1].strip()
                    if next_line and not any(keyword in next_line.upper() for keyword in [
                        'FOR SUCCESSFULLY', 'NSQF', 'LEVEL', 'ISSUED', 'DATE', 'BY', 'HAS COMPLETED', 'CONTRIBUTING',
                        'COURSE', 'PROGRAM', 'CERTIFICATE', 'COMPLETION'
                    ]):
                        learner_name = next_line
                
                if learner_name and len(learner_name) > 2:
                    result["learner_name"] = learner_name
            
            # 8. Google Summer of Code specific patterns
            elif "HAS COMPLETED" in line.upper() and "GOOGLE SUMMER OF CODE" in line.upper():
                # Extract the credential name from the completion statement
                if "Google Summer of Code" in line:
                    import re
                    gsoc_match = re.search(r'Google Summer of Code \d{4}', line)
                    if gsoc_match:
                        result["credential_name"] = gsoc_match.group()
            
            # 9. Google/Program Manager patterns for issuer
            elif "PROGRAM MANAGER" in line.upper() and "GOOGLE" in line.upper():
                result["issuer_name"] = "Google"
            
            # 10. Traditional issuer patterns (fallback)
            elif not result["issuer_name"] and any(keyword in line.lower() for keyword in [
                'university', 'college', 'institute', 'academy', 'school', 'technology', 'google'
            ]):
                result["issuer_name"] = line
            
            # 11. GSoC Date range patterns (JUNE 2 - SEPTEMBER 1, 2025)
            elif any(month in line.upper() for month in ['JUNE', 'JULY', 'AUGUST', 'SEPTEMBER']) and any(pattern in line for pattern in ['-', 'TO', 'THROUGH']):
                result["issued_date"] = line
            
            # 12. Hexadecimal learner ID detection (fallback)
            elif not result["learner_id"] and len(line) >= 16 and all(c in '0123456789abcdef' for c in line.lower()):
                result["learner_id"] = line
            
            # 13. NSQF Level pattern (fallback)
            elif "NSQF LEVEL" in line.upper():
                import re
                level_match = re.search(r'\d+', line)
                if level_match:
                    result["nsqf_level"] = int(level_match.group())
            
            # 14. Date patterns (fallback)
            elif not result["issued_date"] and any(pattern in line for pattern in [
                '2024', '2023', '2025', 'january', 'february', 'march', 'april', 'may', 'june', 
                'july', 'august', 'september', 'october', 'november', 'december'
            ]):
                result["issued_date"] = line
        
        # Clean up and validate results
        result = self._clean_and_validate_results(result)
        return result
    
    def _extract_skills_from_text(self, skills_text: str) -> List[str]:
        """Extract skills from text using various delimiters."""
        import re
        
        # Remove common prefixes and clean text
        skills_text = skills_text.strip()
        
        # Split by various delimiters
        skills = []
        
        # Try comma separation first
        if ',' in skills_text:
            skills = [skill.strip() for skill in skills_text.split(',') if skill.strip()]
        # Try semicolon separation
        elif ';' in skills_text:
            skills = [skill.strip() for skill in skills_text.split(';') if skill.strip()]
        # Try bullet points
        elif '•' in skills_text or '-' in skills_text:
            skills = re.split(r'[•\-]', skills_text)
            skills = [skill.strip() for skill in skills if skill.strip()]
        # Try line breaks
        elif '\n' in skills_text:
            skills = [skill.strip() for skill in skills_text.split('\n') if skill.strip()]
        else:
            # Single skill or space-separated
            skills = [skills_text] if skills_text else []
        
        # Clean up skills
        cleaned_skills = []
        for skill in skills:
            skill = skill.strip()
            if skill and len(skill) > 2:  # Avoid very short skills
                cleaned_skills.append(skill)
        
        return cleaned_skills
    
    def _clean_and_validate_results(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """Clean and validate parsing results."""
        # Remove duplicates from skill tags
        if result["skill_tags"]:
            result["skill_tags"] = list(dict.fromkeys(result["skill_tags"]))  # Preserve order
        
        # Ensure dates are properly formatted
        if result["issued_date"] and ":" in result["issued_date"]:
            result["issued_date"] = result["issued_date"].split(":", 1)[1].strip()
        
        if result["expiry_date"] and ":" in result["expiry_date"]:
            result["expiry_date"] = result["expiry_date"].split(":", 1)[1].strip()
        
        # Set default values if empty
        if not result["credential_name"]:
            result["credential_name"] = "Certificate"
        
        if not result["issuer_name"]:
            result["issuer_name"] = "Unknown Issuer"
        
        if not result["learner_name"]:
            result["learner_name"] = "Unknown Learner"
        
        return result
    
    def _generate_skill_tags(self, certificate_data: Dict[str, Any]) -> List[str]:
        """
        Generate skill tags based on certificate content.
        
        Args:
            certificate_data: Parsed certificate data
            
        Returns:
            List of relevant skill tags
        """
        try:
            skill_tags = []
            title = certificate_data.get("certificate_title", "").upper()
            issuer = certificate_data.get("issuer_name", "").upper()
            
            # AWS-related skills
            if "AWS" in title or "AMAZON" in issuer:
                skill_tags.extend([
                    "AWS Solutions Architect",
                    "Cloud Computing",
                    "Amazon Web Services",
                    "Solutions Architecture",
                    "AWS"
                ])
                
                # Specific AWS services
                if "SOLUTIONS ARCHITECT" in title:
                    skill_tags.extend([
                        "EC2", "S3", "VPC", "RDS", "Lambda", "CloudFormation",
                        "Systems Design", "Cloud Architecture"
                    ])
                elif "DEVELOPER" in title:
                    skill_tags.extend(["AWS Development", "Serverless", "API Gateway", "DynamoDB"])
                elif "SYSOPS" in title:
                    skill_tags.extend(["System Administration", "DevOps", "Monitoring", "Security"])
            
            # Azure-related skills
            elif "AZURE" in title or "MICROSOFT" in issuer:
                skill_tags.extend([
                    "Microsoft Azure",
                    "Cloud Computing",
                    "Azure Solutions",
                    "Cloud Architecture"
                ])
            
            # Google Cloud skills
            elif "GOOGLE CLOUD" in title or "GOOGLE" in issuer:
                skill_tags.extend([
                    "Google Cloud Platform",
                    "Cloud Computing",
                    "GCP Solutions",
                    "Cloud Architecture"
                ])
            
            # Traditional education skills
            elif any(keyword in issuer for keyword in ["UNIVERSITY", "COLLEGE", "INSTITUTE"]):
                skill_tags.extend([
                    "Academic Achievement",
                    "Professional Development",
                    "Skills Certification"
                ])
            
            # Generic certificate skills
            else:
                skill_tags.extend([
                    "Professional Certification",
                    "Skills Validation",
                    "Competency Assessment"
                ])
            
            # Remove duplicates and limit to reasonable number
            return list(dict.fromkeys(skill_tags))[:10]
            
        except Exception as e:
            logger.error(f"Skill tag generation error: {e}")
            return ["Professional Certification"]
    
    def _normalize_date(self, date_str: str) -> str:
        """
        Normalize date string to a standard format.
        
        Args:
            date_str: Raw date string from OCR
            
        Returns:
            Normalized date string in YYYY-MM-DD format or original string if parsing fails
        """
        try:
            import re
            from datetime import datetime
            
            # Clean the date string
            date_str = date_str.strip()
            
            # Common date patterns
            patterns = [
                r'(\d{1,2})[\/\-\.](\d{1,2})[\/\-\.](\d{4})',  # DD/MM/YYYY or DD-MM-YYYY
                r'(\d{4})[\/\-\.](\d{1,2})[\/\-\.](\d{1,2})',  # YYYY/MM/DD or YYYY-MM-DD
                r'(\d{1,2})\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+(\d{4})',  # DD MMM YYYY
                r'(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+(\d{1,2}),?\s+(\d{4})',  # MMM DD, YYYY
                r'(\d{1,2})[th|st|nd|rd]?\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+(\d{4})',  # DDth MMM YYYY
            ]
            
            month_map = {
                'jan': '01', 'feb': '02', 'mar': '03', 'apr': '04', 'may': '05', 'jun': '06',
                'jul': '07', 'aug': '08', 'sep': '09', 'oct': '10', 'nov': '11', 'dec': '12'
            }
            
            for pattern in patterns:
                match = re.search(pattern, date_str, re.IGNORECASE)
                if match:
                    groups = match.groups()
                    
                    if len(groups) == 3:
                        if groups[1].lower() in month_map:  # Month name pattern
                            day, month, year = groups[0], month_map[groups[1].lower()], groups[2]
                            return f"{year}-{month}-{day.zfill(2)}"
                        elif groups[0].lower() in month_map:  # Month first pattern
                            month, day, year = month_map[groups[0].lower()], groups[1], groups[2]
                            return f"{year}-{month}-{day.zfill(2)}"
                        else:  # Numeric pattern
                            if len(groups[0]) == 4:  # YYYY-MM-DD
                                year, month, day = groups[0], groups[1], groups[2]
                            else:  # DD-MM-YYYY
                                day, month, year = groups[0], groups[1], groups[2]
                            return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
            
            # If no pattern matches, try to parse with datetime
            try:
                # Try common formats
                formats = [
                    '%Y-%m-%d', '%d-%m-%Y', '%m/%d/%Y', '%d/%m/%Y',
                    '%Y/%m/%d', '%d.%m.%Y', '%Y.%m.%d'
                ]
                
                for fmt in formats:
                    try:
                        parsed_date = datetime.strptime(date_str, fmt)
                        return parsed_date.strftime('%Y-%m-%d')
                    except ValueError:
                        continue
            except:
                pass
            
            # If all else fails, return original string
            return date_str
            
        except Exception as e:
            logger.warning(f"Date normalization failed for '{date_str}': {e}")
            return date_str
